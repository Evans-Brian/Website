{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "personal use script: Wi9ZVFvPbf_grQ\n",
    "secret:\tvJwRLc9MhDypqom3bM6tALNgx14\n",
    "\n",
    "PRAW stands for Python Reddit API Wrapper, so it makes it very easy for us to access Reddit data. First we connect to Reddit by calling the praw.Reddit function and storing it in a variable. Iâ€™m calling mine reddit. You should pass the following arguments to that function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "from datetime import datetime as dt\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import urllib.request, json\n",
    "#Load in initial data to set time values for CSV\n",
    "\n",
    "\n",
    "#Load in array of teams\n",
    "teamList=[['Buffalo', 'Bills', 'AFC', 'East'],\n",
    "         ['Miami', 'Dolphins', 'AFC', 'East'],\n",
    "         ['New England', 'Patriots', 'AFC', 'East'],\n",
    "         ['New York', 'Jets', 'AFC', 'East'],\n",
    "         ['Baltimore', 'Ravens', 'AFC', 'North'],\n",
    "         ['Cincinnati', 'Bengals', 'AFC', 'North'],\n",
    "         ['Cleveland', 'Browns', 'AFC', 'North'],\n",
    "         ['Pittsburgh', 'Steelers', 'AFC', 'North'],\n",
    "         ['Baltimore', 'Ravens', 'AFC', 'North'],\n",
    "         ['Houston', 'Texans', 'AFC', 'South'],\n",
    "         ['Jacksonville', 'Jaguars', 'AFC', 'South'],\n",
    "         ['Indianapolis', 'Colts', 'AFC', 'South'],\n",
    "         ['Denver', 'Broncos', 'AFC', 'West'],\n",
    "         ['Kansas City', 'Chiefs', 'AFC', 'West'],\n",
    "         ['Oakland', 'Raiders', 'AFC', 'West'],\n",
    "         ['Los Angeles', 'Chargers', 'AFC', 'West'],\n",
    "         ['Dallas', 'Cowboys', 'NFC', 'East'],\n",
    "         ['New York', 'Giants', 'NFC', 'East'],\n",
    "         ['Philadelphia', 'Eagles', 'NFC', 'East'],\n",
    "         ['Washington', 'Redskins', 'NFC', 'East'],\n",
    "         ['Chicago', 'Bears', 'NFC', 'North'],\n",
    "         ['Detroit', 'Lions', 'NFC', 'North'],\n",
    "         ['Green Bay', 'Packers', 'NFC', 'North'],\n",
    "         ['Minnesota', 'Vikings', 'NFC', 'North'],\n",
    "         ['Atlanta', 'Falcons', 'NFC', 'South'],\n",
    "         ['Carolina', 'Panthers', 'NFC', 'South'],\n",
    "         ['New Orleans', 'Saints', 'NFC', 'South'],\n",
    "         ['Tampa Bay', 'Buccaneers', 'NFC', 'South'],\n",
    "         ['Arizona', 'Cardinals', 'NFC', 'West'],\n",
    "         ['Los Angeles', 'Rams', 'NFC', 'West'],\n",
    "         ['San Francisco', '49ers', 'NFC', 'West'],\n",
    "         ['Seattle', 'Seahawks', 'NFC', 'West']]\n",
    "\n",
    "########################\n",
    "with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=browns&aggs=created_utc&frequency=year') as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    yearMentionData = (data['aggs']['created_utc'])\n",
    "    \n",
    "years = []\n",
    "for pair in yearMentionData:\n",
    "    unixTime = pair['key']\n",
    "    dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y')\n",
    "    years.append(dateTime)\n",
    "\n",
    "matrix=[years]\n",
    "\n",
    "for team in teamList:\n",
    "    with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=' + team[1] + '&aggs=created_utc&frequency=year') as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        teamData = (data['aggs']['created_utc'])\n",
    "        teamDataDict = {}\n",
    "\n",
    "        for pair in teamData:\n",
    "            unixTime = pair['key']\n",
    "            dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y')        \n",
    "            teamDataDict[dateTime] = pair['doc_count']\n",
    "\n",
    "        yearCount = []\n",
    "\n",
    "        for time in years:\n",
    "            if time in teamDataDict:\n",
    "                yearCount.append(teamDataDict[time])\n",
    "            else:\n",
    "                yearCount.append(0)\n",
    "        team = team + yearCount\n",
    "        matrix.append(team)\n",
    "\n",
    "\n",
    "matrix[0] = ['City', 'Team', 'Conference', 'Division'] + years\n",
    "\n",
    "\n",
    "with open('nflYear.csv', mode='w') as teams:\n",
    "    writer = csv.writer(teams, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for row in matrix:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "##################################\n",
    "\n",
    "with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=browns&aggs=created_utc&frequency=month') as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    monthMentionData = (data['aggs']['created_utc'])\n",
    "    \n",
    "months = []\n",
    "for pair in monthMentionData:\n",
    "    unixTime = pair['key']\n",
    "    dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y-%m')\n",
    "    months.append(dateTime)\n",
    "matrix=[months]\n",
    "\n",
    "for team in teamList:\n",
    "    with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=' + team[1] + '&aggs=created_utc&frequency=month') as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        teamData = (data['aggs']['created_utc'])\n",
    "        teamDataDict = {}\n",
    "\n",
    "        for pair in teamData:\n",
    "            unixTime = pair['key']\n",
    "            dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y-%m')        \n",
    "            teamDataDict[dateTime] = pair['doc_count']\n",
    "\n",
    "        monthCount = []\n",
    "\n",
    "        for time in months:\n",
    "            if time in teamDataDict:\n",
    "                monthCount.append(teamDataDict[time])\n",
    "            else:\n",
    "                monthCount.append(0)\n",
    "        team = team + monthCount\n",
    "        matrix.append(team)\n",
    "\n",
    "\n",
    "matrix[0] = ['City', 'Team', 'Conference', 'Division'] + months\n",
    "\n",
    "\n",
    "with open('nflMonth.csv', mode='w') as teams:\n",
    "    writer = csv.writer(teams, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for row in matrix:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "##############################################################\n",
    "\n",
    "with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=browns&aggs=created_utc&frequency=week') as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    weekMentionData = (data['aggs']['created_utc'])\n",
    "\n",
    "weeks = []\n",
    "for pair in weekMentionData:\n",
    "    unixTime = pair['key']\n",
    "    dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y-%m-%W')\n",
    "    weeks.append(dateTime)\n",
    "matrix=[weeks]\n",
    "\n",
    "for team in teamList:\n",
    "    with urllib.request.urlopen('https://api.pushshift.io/reddit/comment/search?before=1551228873&after=1262307661&subreddit=nfl&q=' + team[1] + '&aggs=created_utc&frequency=week') as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        teamData = (data['aggs']['created_utc'])\n",
    "        teamDataDict = {}\n",
    "\n",
    "        for pair in teamData:\n",
    "            unixTime = pair['key']\n",
    "            dateTime = dt.utcfromtimestamp(unixTime).strftime('%Y-%m-%W')\n",
    "            teamDataDict[dateTime] = pair['doc_count']\n",
    "\n",
    "        weekCount = []\n",
    "\n",
    "        for time in weeks:\n",
    "            if time in teamDataDict:\n",
    "                weekCount.append(teamDataDict[time])\n",
    "            else:\n",
    "                weekCount.append(0)\n",
    "        team = team + weekCount\n",
    "        matrix.append(team)\n",
    "\n",
    "\n",
    "matrix[0] = ['City', 'Team', 'Conference', 'Division'] + weeks\n",
    "\n",
    "\n",
    "with open('nflWeek.csv', mode='w') as teams:\n",
    "    writer = csv.writer(teams, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "    for row in matrix:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
