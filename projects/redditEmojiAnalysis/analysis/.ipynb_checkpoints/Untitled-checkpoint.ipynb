{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataisbeautiful\n",
      "   score  emojiCount  profanityCount  wordCount binnedScore binnedEmojiCount  \\\n",
      "0      1           1               0         19           0                1   \n",
      "1     14           0               0         13           1                0   \n",
      "2      1           0               1         24           0                0   \n",
      "3      1           2               0         12           0                2   \n",
      "4      3           0               1         33           1                0   \n",
      "\n",
      "  binnedprofanityCount binnedWordCount  \n",
      "0                    0               2  \n",
      "1                    0               2  \n",
      "2                    1               2  \n",
      "3                    0               2  \n",
      "4                    1               2  \n",
      "             score   emojiCount  profanityCount    wordCount\n",
      "count  1500.000000  1500.000000     1500.000000  1500.000000\n",
      "mean     19.310000     2.398000        0.418000    43.613333\n",
      "std     151.918162    71.526822        0.640481    97.389940\n",
      "min     -41.000000     0.000000        0.000000     1.000000\n",
      "25%       1.000000     0.000000        0.000000     9.000000\n",
      "50%       1.000000     0.000000        0.000000    22.000000\n",
      "75%       3.000000     1.000000        1.000000    45.000000\n",
      "max    4389.000000  2770.000000        5.000000  2420.000000\n",
      "[[0.08622998 0.35888387 0.55488615]\n",
      " [0.09890091 0.35283008 0.54826902]\n",
      " [0.13693235 0.25149463 0.61157302]\n",
      " ...\n",
      " [0.15129935 0.33785748 0.51084317]\n",
      " [0.08622998 0.35888387 0.55488615]\n",
      " [0.09890091 0.35283008 0.54826902]]\n",
      "     binnedEmojiCount binnedprofanityCount binnedWordCount  predicted  \\\n",
      "471                 0                    0               2          1   \n",
      "9                   1                    0               2          1   \n",
      "1499                1                    1               2          1   \n",
      "54                  2                    0               0          0   \n",
      "1411                0                    1               2          1   \n",
      "1157                1                    0               2          1   \n",
      "737                 0                    1               2          1   \n",
      "175                 0                    1               2          1   \n",
      "260                 0                    0               0          0   \n",
      "1417                1                    0               2          1   \n",
      "1370                0                    1               2          1   \n",
      "1256                0                    0               2          1   \n",
      "1346                0                    1               2          1   \n",
      "187                 0                    1               2          1   \n",
      "720                 1                    0               2          1   \n",
      "674                 0                    0               0          0   \n",
      "1308                0                    0               0          0   \n",
      "1421                0                    1               2          1   \n",
      "364                 0                    1               2          1   \n",
      "1000                0                    0               2          1   \n",
      "182                 0                    1               2          1   \n",
      "646                 1                    0               2          1   \n",
      "82                  0                    0               2          1   \n",
      "436                 0                    2               2          1   \n",
      "1120                0                    1               2          1   \n",
      "828                 2                    0               0          0   \n",
      "1136                0                    0               0          0   \n",
      "535                 0                    1               2          1   \n",
      "915                 1                    0               2          1   \n",
      "1259                0                    0               2          1   \n",
      "...               ...                  ...             ...        ...   \n",
      "839                 0                    2               2          1   \n",
      "958                 0                    1               2          1   \n",
      "752                 0                    2               2          1   \n",
      "575                 1                    0               2          1   \n",
      "77                  0                    1               2          1   \n",
      "459                 0                    0               2          1   \n",
      "1188                0                    0               2          1   \n",
      "1073                0                    0               2          1   \n",
      "44                  0                    1               2          1   \n",
      "1234                0                    1               2          1   \n",
      "245                 1                    0               2          1   \n",
      "1463                0                    0               2          1   \n",
      "300                 0                    0               2          1   \n",
      "703                 1                    0               2          1   \n",
      "693                 0                    1               2          1   \n",
      "276                 1                    0               2          1   \n",
      "921                 2                    0               2          1   \n",
      "553                 0                    2               2          1   \n",
      "402                 0                    0               2          1   \n",
      "269                 0                    1               2          1   \n",
      "1099                0                    0               2          1   \n",
      "494                 1                    0               2          1   \n",
      "1487                0                    1               2          1   \n",
      "1131                0                    0               0          0   \n",
      "641                 0                    0               0          0   \n",
      "283                 0                    0               2          1   \n",
      "1042                0                    1               2          1   \n",
      "867                 2                    0               2          1   \n",
      "399                 0                    0               2          1   \n",
      "271                 1                    0               2          1   \n",
      "\n",
      "     binnedScore  \n",
      "471            0  \n",
      "9              1  \n",
      "1499           0  \n",
      "54             0  \n",
      "1411           0  \n",
      "1157           1  \n",
      "737            0  \n",
      "175            1  \n",
      "260            0  \n",
      "1417          -1  \n",
      "1370           1  \n",
      "1256           1  \n",
      "1346          -1  \n",
      "187            1  \n",
      "720            1  \n",
      "674            0  \n",
      "1308           0  \n",
      "1421           0  \n",
      "364            1  \n",
      "1000           1  \n",
      "182            0  \n",
      "646            1  \n",
      "82             0  \n",
      "436            0  \n",
      "1120           1  \n",
      "828            1  \n",
      "1136           0  \n",
      "535            0  \n",
      "915            1  \n",
      "1259           1  \n",
      "...          ...  \n",
      "839            1  \n",
      "958            1  \n",
      "752            0  \n",
      "575            1  \n",
      "77             1  \n",
      "459            0  \n",
      "1188          -1  \n",
      "1073          -1  \n",
      "44             1  \n",
      "1234           1  \n",
      "245            1  \n",
      "1463           0  \n",
      "300            0  \n",
      "703            1  \n",
      "693           -1  \n",
      "276            0  \n",
      "921           -1  \n",
      "553            1  \n",
      "402            1  \n",
      "269            1  \n",
      "1099           1  \n",
      "494            1  \n",
      "1487           1  \n",
      "1131           0  \n",
      "641            0  \n",
      "283            1  \n",
      "1042           0  \n",
      "867            0  \n",
      "399            0  \n",
      "271            0  \n",
      "\n",
      "[500 rows x 5 columns]\n",
      "0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Brian\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csvs = glob.glob('C:\\\\Users\\\\Brian\\\\Documents\\\\Career\\\\Website\\\\personalSite\\\\projects\\\\redditEmojiAnalysis\\\\analysis\\\\data\\\\*.csv')\n",
    "  \n",
    "file = csvs[0]\n",
    "df = pd.read_csv(file)\n",
    "print(df['subreddit'][0])\n",
    "del df['subreddit']\n",
    "\n",
    "df['binnedScore'] = pd.cut(df['score'], bins=[float(\"-inf\"), .9, 1.1, float(\"inf\")], labels = [-1, 0, 1])\n",
    "df['binnedEmojiCount'] = pd.cut(df['emojiCount'], bins=[-1, .9, 1.1, float(\"inf\")], labels = [0, 1, 2])\n",
    "df['binnedprofanityCount'] = pd.cut(df['profanityCount'], bins=[-1, .9, 1.1, float(\"inf\")], labels = [0, 1, 2])\n",
    "df['binnedWordCount'] = pd.cut(df['wordCount'], bins=[0, 5, float(\"inf\")], labels = [0, 2])\n",
    "print(df.head())\n",
    "# for idx, row in df.iterrows():  \n",
    "#     if  df.loc[idx,'score'] > 1:\n",
    "#         df.loc[idx,'score'] = 2\n",
    "#     elif df.loc[idx,'score'] < 1:\n",
    "#         df.loc[idx,'score'] = 0\n",
    "        \n",
    "#     if  df.loc[idx,'emojiCount'] > 1:\n",
    "#         df.loc[idx,'emojiCount'] = 2\n",
    "        \n",
    "#     if  df.loc[idx,'profanityCount'] > 1:\n",
    "#         df.loc[idx,'profanityCount'] = 2\n",
    "        \n",
    "#     if  df.loc[idx,'wordCount'] > 50:\n",
    "#         df.loc[idx,'wordCount'] = 1\n",
    "#     else:\n",
    "#         df.loc[idx,'wordCount'] = 0\n",
    "\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "x = df[['binnedEmojiCount', 'binnedprofanityCount', 'binnedWordCount']]\n",
    "\n",
    "y = df['binnedScore']\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict Output \n",
    "predicted = model.predict(xTest)\n",
    "predictedProb = model.predict_proba(xTest)\n",
    "print(predictedProb)\n",
    "xTest['predicted'] = predicted\n",
    "xTest['binnedScore'] = yTest\n",
    "\n",
    "print(xTest)\n",
    "score = accuracy_score(yTest, predicted)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataisbeautiful\n",
      "   score  emojiCount  profanityCount  wordCount binnedScore binnedEmojiCount  \\\n",
      "0      1           1               0         19        zero                1   \n",
      "1     14           0               0         13    positive             zero   \n",
      "2      1           0               1         24        zero             zero   \n",
      "3      1           2               0         12        zero               2+   \n",
      "4      3           0               1         33    positive             zero   \n",
      "\n",
      "  binnedprofanityCount binnedWordCount  \n",
      "0                 zero              6+  \n",
      "1                 zero              6+  \n",
      "2                    1              6+  \n",
      "3                 zero              6+  \n",
      "4                    1              6+  \n",
      "             score   emojiCount  profanityCount    wordCount\n",
      "count  1500.000000  1500.000000     1500.000000  1500.000000\n",
      "mean     19.310000     2.398000        0.418000    43.613333\n",
      "std     151.918162    71.526822        0.640481    97.389940\n",
      "min     -41.000000     0.000000        0.000000     1.000000\n",
      "25%       1.000000     0.000000        0.000000     9.000000\n",
      "50%       1.000000     0.000000        0.000000    22.000000\n",
      "75%       3.000000     1.000000        1.000000    45.000000\n",
      "max    4389.000000  2770.000000        5.000000  2420.000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'zero'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-66660ce2fde3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Train the model using the training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#Predict Output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \"\"\"\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'zero'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csvs = glob.glob('C:\\\\Users\\\\Brian\\\\Documents\\\\Career\\\\Website\\\\personalSite\\\\projects\\\\redditEmojiAnalysis\\\\analysis\\\\data\\\\*.csv')\n",
    "  \n",
    "file = csvs[0]\n",
    "df = pd.read_csv(file)\n",
    "print(df['subreddit'][0])\n",
    "del df['subreddit']\n",
    "\n",
    "df['binnedScore'] = pd.cut(df['score'], bins=[float(\"-inf\"), .9, 1.1, float(\"inf\")], labels = ['negative', 'zero', 'positive'])\n",
    "df['binnedEmojiCount'] = pd.cut(df['emojiCount'], bins=[-1, .9, 1.1, float(\"inf\")], labels = ['zero', '1', '2+'])\n",
    "df['binnedprofanityCount'] = pd.cut(df['profanityCount'], bins=[-1, .9, 1.1, float(\"inf\")], labels = ['zero', '1', '2+'])\n",
    "df['binnedWordCount'] = pd.cut(df['wordCount'], bins=[0, 5, float(\"inf\")], labels = ['0-5', '6+'])\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "x = df[['binnedEmojiCount', 'binnedprofanityCount', 'binnedWordCount']]\n",
    "\n",
    "y = df['binnedScore']\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 1/3, random_state = 0)\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training sets \n",
    "model.fit(xTrain, yTrain)\n",
    "\n",
    "#Predict Output \n",
    "predicted = model.predict(xTest)\n",
    "predictedProb = model.predict_proba(xTest)\n",
    "print(predictedProb)\n",
    "xTest['predicted'] = predicted\n",
    "xTest['binnedScore'] = yTest\n",
    "\n",
    "print(xTest)\n",
    "score = accuracy_score(yTest, predicted)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
